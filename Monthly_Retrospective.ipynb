{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Retrospective script\n",
    "The following script will produce a list of statistics that might be relevant for the Monthly retrospective. **This new version uses the Geonet API and can therefore be run on the first!**\n",
    "\n",
    "All you need to do is change the dates to the correct month in the box below and select \"run all cells\".\n",
    "\n",
    "This is a work in progress and would appreciate any feedback as to what other information, graphs etc would be useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modules to import\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Times\n",
    "Change the date here. Because it is in UTC time, start it on the last day of the previous month and end it on the last of the current month. \n",
    "During daylight savings time (Summer), midnight NZT is at at 11:00:00, otherwise set it to 12:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = \"2019-12-31T11:00:00\" #change the 12:00:00 for daylight savings. Be sure to leave the T.\n",
    "endtime = \"2020-01-31T11:00:00\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section is the code that will automatically run with the above input. The output is found at the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a JSON file which contains earthquake information. The query is generated through the WFS service off Geonet\n",
    "#the inputs starttime and endtime define the times\n",
    "jase = requests.get(\n",
    "    \"http://wfs.geonet.org.nz/geonet/ows?service=WFS&version=1.0.0&request=\"\n",
    "    \"GetFeature&typeName=geonet:quake_search_v1&outputFormat=json&cql_filter=origintime>=\" \n",
    "    + starttime + \"+AND+origintime<=\" +endtime).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            count\n",
      "magnitudes       \n",
      "0-1            86\n",
      "1-2           706\n",
      "2-3           725\n",
      "3-4           139\n",
      "4-5           119\n",
      "5-6            39\n",
      "6-7             4\n",
      "7-8             1\n",
      "8+              0\n",
      "\n",
      "Total quakes:  1819 \n",
      "Local 1691 \n",
      "Kermadec:  77 \n",
      "Teleseismics:  51 \n",
      "Maxmimum magnitude 7.62015079  ID:  2020p075132 \n",
      "Minimum magnitude 0.1906136424 ID:  2020p030715\n"
     ]
    }
   ],
   "source": [
    "lat, lon, mag, quakeid = [[] for x in range(4)] #empty lists to iterate to\n",
    "#the following is a for loop which populates above lists with values from JSON\n",
    "for a in range(len(jase['features'])):\n",
    "    lon.append(jase['features'][a]['geometry']['coordinates'][0])\n",
    "    lat.append(jase['features'][a]['geometry']['coordinates'][1])\n",
    "    mag.append(jase['features'][a]['properties']['magnitude'])\n",
    "    quakeid.append(jase['features'][a]['properties']['publicid'])\n",
    "#dataframe containing above information\n",
    "df = pd.DataFrame({\"latitude\":lat,\"longitude\":lon,\"magnitude\":mag,\"quake_id\":quakeid})\n",
    "#empty Dataframe for following functions\n",
    "summary_df = pd.DataFrame({})\n",
    "#setting bins for magnitude summary\n",
    "summary_df['magnitudes'] = [\"0-1\", \"1-2\",\"2-3\",\"3-4\",\"4-5\",\"5-6\",\"6-7\",\"7-8\",\"8+\"]\n",
    "#counting magnitude by bin\n",
    "summary_df['count'] = (df['magnitude'].value_counts(bins = [0,1,2,3,4,5,6,7,8,9]))\n",
    "summary_df = summary_df.sort_index()\n",
    "#setting index as bins defined above\n",
    "summary_df = summary_df.set_index('magnitudes')\n",
    "\n",
    "print(summary_df)\n",
    "#count number of events within Kermadec SOP zone\n",
    "kermadec = df[(df['latitude'] <=-25) & (df['latitude']>=-33) & \n",
    "              (df['longitude'] >= 177) & (df['longitude'] <=180) | \n",
    "              (df['latitude'] <=-25) & (df['latitude']>=-33) & \n",
    "              (df['longitude'] >= -180) & (df['longitude'] <=-169)]\n",
    "#count number of events within Local SOP zone\n",
    "local = df[(df['latitude'] <=-33) & (df['latitude'] >= -50) & \n",
    "           (df['longitude'] >= 163) & (df['longitude'] <=180) | \n",
    "           (df['latitude'] <=-33) & (df['latitude'] >= -50) & \n",
    "           (df['longitude'] >= -180) & (df['longitude'] <=-175)|\n",
    "           (df['latitude'] <=-32) & (df['latitude'] >= -33) & \n",
    "           (df['longitude'] >= 163) & (df['longitude'] <=177)]\n",
    "#print results, tele calculated as total minue kermadec and local quakes\n",
    "print(\"\\nTotal quakes: \", len(df), \"\\nLocal\", len(local), \"\\nKermadec: \", \n",
    "      len(kermadec), \"\\nTeleseismics: \", len(df) - len(kermadec) - len(local),\n",
    "     \"\\nMaxmimum magnitude\", df['magnitude'].max(), \" ID: \", \n",
    "      df.iloc[df['magnitude'].idxmax()]['quake_id'], \"\\nMinimum magnitude\",\n",
    "      df['magnitude'].min(), \"ID: \", df.iloc[df['magnitude'].idxmin()]['quake_id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ngmc",
   "language": "python",
   "name": "ngmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
